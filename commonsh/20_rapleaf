
# A common rapleaf environment
# This should be called from .bashrc
# for rapleaf and anyone in the rapleaf group
umask 002

export RAPREDUCE_LIB=/apps/rapreduce/current/lib
export RAPREDUCE_APPS=/apps/rapreduce_apps/current/rapreduce
export JAVA_HOME=/usr/java/latest
export SVN=https://svn.vpn.rapleaf.com/main
export RAP=$SVN/rapleaf.com
export SVN_EDITOR=/usr/bin/vim
export JARS_HOME=/apps/jars/current
export NFS=/var/nfs/mounts

# The TF cluster is special because of the Hadoop RPMS
# it doesn't need these variables
#if  [ ! `hostname -s | grep -e "^tf[0-9]" -e "^tf-*" -e "ds*"` ]; then
#	export HADOOP_HOME=/apps/hadoop
#	export HADOOP_CONF_DIR=$HADOOP_HOME/conf
#fi

# set the mysql prompt.  note setting it in the .my.cnf doesn't
# work right because \h (hostname) evaluates to 'localhost'
export MYSQL_PS1="\u@$HOST> "

# do not save duplicates in history and do not save
# command that start with a space
export HISTCONTROL=ignoreboth

export HADOOP_HOME=/usr/lib/hadoop
export HADOOP_CONF_DIR=$HADOOP_HOME/conf

# We put NFS bin first so we can hijack some things like 'exit' and 'crontab'
# We put sbins in our path so we can just type 'sudo lsof...'
export PATH=/var/nfs/mounts/bin:$PATH:/usr/kerberos/sbin:/usr/local/sbin:/sbin:/usr/sbin:$HADOOP_HOME/bin:$JAVA_HOME/bin:$ANT_HOME/bin:$AWS_CLOUDWATCH_HOME/bin:/opt/ruby-enterprise/bin:/opt/ruby-enterprise/lib/ruby/gems/1.8/bin:$HADOOP_HOME/bin
export rapsvn="https://svn.vpn.rapleaf.com/main"

alias hadoop="/usr/lib/hadoop-0.20/bin/hadoop"
alias hdfs='hadoop dfs'
alias pw='ssh rapmaster "sudo cat /apps/deploy/figg/figg_private/misc_passwds"'

